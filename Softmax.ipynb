{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST - Softmax model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf # tensor flow\n",
    "from keras.utils.np_utils import to_categorical # one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration parameter\n",
    "TRAINING_ITERATIONS = 100000\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data from CSV file\n",
    "dataset = pd.read_csv(\"./data/train.csv\")\n",
    "x_train = dataset.iloc[:,1:].values.astype('float32')\n",
    "y_train = dataset.iloc[:,0].values.astype('float32')\n",
    "y_train = to_categorical(y_train)\n",
    "y_train = y_train.astype(np.uint8)\n",
    "x_ = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an expample from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3475c68f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test = x_train[2,:].reshape(28,28)\n",
    "plt.imshow(test, cmap=plt.get_cmap('gray'))\n",
    "plt.title(y_train[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.multiply(x_train, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = y_train.shape[0]\n",
    "\n",
    "def next_batch(batch_size, i):\n",
    "    global x_train\n",
    "    global y_train\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly\n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        x_train = x_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    end = index_in_epoch\n",
    "    return x_train[start:end], y_train[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x_, W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss func\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.00# convert from [0:255] => [0.0:1.0]\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "print('test_images({0[0]},{0[1]})'.format(test_images.shape)01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy => 0.5078 for step 0\n",
      "training_accuracy => 0.5234 for step 1\n",
      "training_accuracy => 0.4531 for step 2\n",
      "training_accuracy => 0.4219 for step 3\n",
      "training_accuracy => 0.3906 for step 4\n",
      "training_accuracy => 0.5156 for step 5\n",
      "training_accuracy => 0.6719 for step 6\n",
      "training_accuracy => 0.4844 for step 7\n",
      "training_accuracy => 0.4766 for step 8\n",
      "training_accuracy => 0.5234 for step 9\n",
      "training_accuracy => 0.5703 for step 10\n",
      "training_accuracy => 0.8203 for step 20\n",
      "training_accuracy => 0.7891 for step 30\n",
      "training_accuracy => 0.7422 for step 40\n",
      "training_accuracy => 0.7734 for step 50\n",
      "training_accuracy => 0.7344 for step 60\n",
      "training_accuracy => 0.7734 for step 70\n",
      "training_accuracy => 0.7344 for step 80\n",
      "training_accuracy => 0.7500 for step 90\n",
      "training_accuracy => 0.7422 for step 100\n",
      "training_accuracy => 0.7969 for step 200\n",
      "training_accuracy => 0.8828 for step 300\n",
      "training_accuracy => 0.8828 for step 400\n",
      "training_accuracy => 0.8906 for step 500\n",
      "training_accuracy => 0.9062 for step 600\n",
      "training_accuracy => 0.8281 for step 700\n",
      "training_accuracy => 0.9141 for step 800\n",
      "training_accuracy => 0.8594 for step 900\n",
      "training_accuracy => 0.8438 for step 1000\n",
      "training_accuracy => 0.8516 for step 2000\n",
      "training_accuracy => 0.9141 for step 3000\n",
      "training_accuracy => 0.9297 for step 4000\n",
      "training_accuracy => 0.9219 for step 5000\n",
      "training_accuracy => 0.8984 for step 6000\n",
      "training_accuracy => 0.8828 for step 7000\n",
      "training_accuracy => 0.8828 for step 8000\n",
      "training_accuracy => 0.8906 for step 9000\n",
      "training_accuracy => 0.8906 for step 10000\n",
      "training_accuracy => 0.9297 for step 20000\n",
      "training_accuracy => 0.9297 for step 30000\n",
      "training_accuracy => 0.9297 for step 40000\n",
      "training_accuracy => 0.8906 for step 50000\n",
      "training_accuracy => 0.9453 for step 60000\n",
      "training_accuracy => 0.9219 for step 70000\n",
      "training_accuracy => 0.9141 for step 80000\n",
      "training_accuracy => 0.9141 for step 90000\n",
      "training_accuracy => 0.9375 for step 99999\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "display_step = 1\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "    batch_xs, batch_ys = next_batch(BATCH_SIZE, i)\n",
    "    sess.run(train_step, feed_dict={x_: batch_xs, y_: batch_ys})\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    if i % display_step == 0 or (i + 1) == TRAINING_ITERATIONS:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x_: batch_xs, y_: batch_ys})\n",
    "        print('training_accuracy => %.4f for step %d' % (train_accuracy, i))\n",
    "        \n",
    "        # increase display_step\n",
    "        if i % (display_step * 10) == 0 and i:\n",
    "            display_step *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read testing data from CSV file\n",
    "x_test = pd.read_csv(\"./data/test.csv\").values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from [0:255] => [0.0:1.0]\n",
    "x_test = np.multiply(x_test, 1.0 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set\n",
    "predict = tf.argmax(y, 1)\n",
    "y_test = sess.run(predict, feed_dict={x_: x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "np.savetxt('submission.csv',\n",
    "           np.c_[range(1, len(x_test) + 1), y_test],\n",
    "           delimiter=',',\n",
    "           header='ImageId,Label',\n",
    "           comments='',\n",
    "           fmt='%d')\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
